---
title: Evaluation
tags: ['sectionHead']
---

> Time and money are always highly prized commodities. There is always a surplus of great ideas, and never enough time and money to implement them. So why, you may wonder, would you want to adopt more measurement work? The answer is that by showing how your work is delivering your mission, you make your organization more accountable, more likely to receive funding, and more attractive to staff, volunteers, members, and donors. Most importantly, by measuring the extent to which your work succeeds, you will be able to improve your programs in concrete and measurable ways that make a real difference to the people you serve. Without this, improvement is ad hoc guesswork, at best. <br/><br/>— [Outcome Measurement: An Introduction to Mission Delivery](https://charityvillage.com/outcome_measurement_an_introduction_to_mission_delivery/){:target="_blank"}



Much of the time, your information needs can be met with one or two assessments. Other times, you have a bigger, deeper question that an assessment can address. In these cases, you can perform an evaluation. An evaluation makes a judgment about something, such as the value, quality, or efficacy of a program, partnership, or other activity, to provide information that will help with a decision about some future action.<sup>1</sup> It begins with questions, finds answers, and ends with conclusions or recommendations. The questions you have will help determine the type of evaluation you choose and how you use it. As you design your evaluation, think about the following factors:

- Why are you conducting an evaluation?
- Who are you doing it for?
- How do you want the findings to be used?

The **utilization-focused** approach to evaluation maintains that an evaluation is only as good as it is useful. Design your evaluation in a way that will maximize its usefulness to its intended audience—whether that is your manager, a funder, a partner, or yourself. Learn more at [BetterEvaluation.org](http://www.betterevaluation.org/en/plan/approach/utilization_focused_evaluation){:target="_blank"}.

## Stakeholders

An evaluation can have several stakeholders. After yourself, the most prominent group of stakeholders is the audience for the final report—often composed of managers, funders, or other authority figures. Of course, they are not your only stakeholders and may not even be the most important ones. Other stakeholders may include:

- Other library staff who worked on the project or who may work on the project (or similar projects) in the future
- Any partners who worked with you
- Participants in the program, as well as their parents.
- Other community members who are impacted by the initiative.
- People who may want to participate in the future -- or who you want to participate in the future.

Your stakeholders should be involved in the evaluation process—defining values, identifying essential measures, and collecting or providing data. They may have different perspectives on what the outcomes should be and ways to measure them. You may not be able to speak to every individual stakeholder, but try to get input from representatives of each group, at least. However, don’t fall into the trap of thinking you have to follow every recommendation from every group — as the saying goes, if you try to please everyone, you end up pleasing no one. The purpose of an evaluation is to inform a decision, not dictate the path forward.<sup>2</sup>

The answer to the question should be something one or more of your stakeholder groups can use to make a decision (such as continuing to fund a program or ending a partnership).

Stakeholders should always be involved in an evaluation, providing context, advice, and feedback about the evaluation. **Participatory evaluation** takes stakeholder participation to the next level and actively involves stakeholders in the process of planning and carrying out the evaluation. To learn more about participatory evaluation, see Chapter 36, Section 2 of the [Community Toolbox: Community-Based Participatory Research](http://ctb.ku.edu/en/table-of-contents/evaluate/evaluation/intervention-research/main){:target="_blank"}.

---
<details>
	<summary>References</summary>
	<p>1: <a href="https://doi.org/10.17226/12614" target="_blank">Surrounded by Science: Learning Science in Informal Environments</a> by Marilyn Fenichel and Heidi A. Schweingruber, p. 111. National Academies Press, 2010.</p>
 	<p>2: <a href="http://www.informalscience.org/evaluation/pi-guide" target="_blank">Principal Investigator’s Guide: Managing Evaluation in Informal STEM Education Projects</a>, by R. Bonney, K. Ellenbogen, L. Goodyear, & R. Hellenga, pp. 3-4. Center for Advancement of Informal Science Education, 2001.</p>
</details>